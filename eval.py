"""
è¯„ä¼° Pipeline - å®Œå…¨å¯ä»¥å…±ç”¨çš„éƒ¨åˆ†
==================================================
ä» frozen encoder æŠ½ feature â†’ å»º k-NN feature bank â†’ åœ¨ eval ä¸Šç®— accuracy
æˆ– linear probe
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import pandas as pd
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from tqdm import tqdm


# ============================================================
# 1. ç‰¹å¾æå–
# ============================================================

def extract_features(
    model: nn.Module,
    dataloader: DataLoader,
    device: torch.device,
    use_cls_token: bool = False,
    disable_tqdm: bool = False
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    ä» frozen encoder æå–ç‰¹å¾
    
    Args:
        model: ç¼–ç å™¨æ¨¡å‹ï¼ˆbackbone æˆ– backbone + head çš„ä¸€éƒ¨åˆ†ï¼‰
        dataloader: æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        use_cls_token: æ˜¯å¦ä½¿ç”¨ CLS tokenï¼ˆViTï¼‰
        disable_tqdm: æ˜¯å¦ç¦ç”¨ tqdm è¿›åº¦æ¡
    
    Returns:
        features: [N, feat_dim] ç‰¹å¾çŸ©é˜µ
        labels: [N] æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ï¼‰
    """
    model.eval()
    features = []
    labels = []
    
    with torch.no_grad():
        iterator = dataloader if disable_tqdm else tqdm(dataloader, desc="æå–ç‰¹å¾")
        for batch in iterator:
            if isinstance(batch, (list, tuple)) and len(batch) == 2:
                images, batch_labels = batch
                # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šåœ¨ GPU ä¸Šç´¯ç§¯æ ‡ç­¾ï¼Œæœ€åä¸€æ¬¡æ€§ç§»åˆ° CPU
                labels.append(batch_labels)  # ä¿æŒåœ¨ GPU ä¸Š
            else:
                images = batch
                if isinstance(images, (list, tuple)):
                    images = images[0]  # å¦‚æœæ˜¯ viewsï¼Œå–ç¬¬ä¸€ä¸ª
            
            images = images.to(device)
            
            # æå–ç‰¹å¾
            if hasattr(model, 'forward_features'):
                # æŸäº›æ¨¡å‹å¯èƒ½æœ‰ forward_features æ–¹æ³•
                feat = model.forward_features(images)
            else:
                feat = model(images)
            
            # å¤„ç† ViT çš„ CLS token
            # å¯¹äº ViTï¼ˆ3D è¾“å‡ºï¼‰ï¼Œæ€»æ˜¯å– CLS tokenï¼ˆç¬¬ 0 ä¸ª tokenï¼‰
            # use_cls_token å‚æ•°ä¸»è¦ç”¨äºæ§åˆ¶æ˜¯å¦æ˜¾å¼æŒ‡å®šä½¿ç”¨ CLS token
            if len(feat.shape) == 3:
                # [B, num_tokens, feat_dim] -> [B, feat_dim] (å– CLS token)
                # ViT è¾“å‡º: [B, num_patches+1, feat_dim]ï¼Œç¬¬ 0 ä¸ªæ˜¯ CLS token
                feat = feat[:, 0]
            elif len(feat.shape) != 2:
                # å¦‚æœä¸æ˜¯ 2D æˆ– 3Dï¼ŒæŠ¥é”™
                raise ValueError(f"Unexpected feature shape: {feat.shape}, expected 2D [B, D] or 3D [B, N, D]")
            
            # å½’ä¸€åŒ–
            feat = F.normalize(feat, dim=1)
            
            # æ£€æŸ¥ NaN å’Œ Inf
            if torch.isnan(feat).any() or torch.isinf(feat).any():
                print(f"âš ï¸  Warning: NaN/Inf detected in features, replacing with zeros")
                feat = torch.nan_to_num(feat, nan=0.0, posinf=1.0, neginf=-1.0)
                # é‡æ–°å½’ä¸€åŒ–
                feat = F.normalize(feat, dim=1)
            
            # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šåœ¨ GPU ä¸Šç´¯ç§¯ç‰¹å¾ï¼Œæœ€åä¸€æ¬¡æ€§ç§»åˆ° CPU
            features.append(feat)  # ä¿æŒåœ¨ GPU ä¸Š
    
    # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šåœ¨ GPU ä¸Šæ‹¼æ¥ï¼Œç„¶åä¸€æ¬¡æ€§ç§»åˆ° CPU
    features = torch.cat(features, dim=0).cpu().numpy()
    
    # æœ€ç»ˆæ£€æŸ¥ NaN
    if np.isnan(features).any() or np.isinf(features).any():
        print(f"âš ï¸  Warning: NaN/Inf in final features, replacing with zeros")
        features = np.nan_to_num(features, nan=0.0, posinf=1.0, neginf=-1.0)
        # é‡æ–°å½’ä¸€åŒ–
        norms = np.linalg.norm(features, axis=1, keepdims=True)
        norms = np.where(norms == 0, 1.0, norms)  # é¿å…é™¤ä»¥0
        features = features / norms
    
    # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šå¦‚æœæœ‰æ ‡ç­¾ï¼Œåœ¨ GPU ä¸Šæ‹¼æ¥åä¸€æ¬¡æ€§ç§»åˆ° CPU
    if labels and len(labels) > 0:
        if isinstance(labels[0], torch.Tensor):
            # æ ‡ç­¾æ˜¯ GPU tensorï¼Œåœ¨ GPU ä¸Šæ‹¼æ¥
            labels = torch.cat(labels, dim=0).cpu().numpy()
        else:
            # æ ‡ç­¾å·²ç»æ˜¯ numpyï¼Œç›´æ¥è½¬æ¢
            labels = np.array(labels)
    else:
        labels = None
    
    return features, labels


# ============================================================
# 2. k-NN è¯„ä¼°
# ============================================================

def knn_eval(
    train_features: np.ndarray,
    train_labels: np.ndarray,
    val_features: np.ndarray,
    val_labels: np.ndarray,
    k: int = 20
) -> float:
    """
    ä½¿ç”¨ k-NN åœ¨ç‰¹å¾ç©ºé—´ä¸Šè¯„ä¼°
    
    Args:
        train_features: [N_train, feat_dim] è®­ç»ƒé›†ç‰¹å¾
        train_labels: [N_train] è®­ç»ƒé›†æ ‡ç­¾
        val_features: [N_val, feat_dim] éªŒè¯é›†ç‰¹å¾
        val_labels: [N_val] éªŒè¯é›†æ ‡ç­¾
        k: k-NN çš„ k å€¼
    
    Returns:
        accuracy: å‡†ç¡®ç‡
    """
    print(f"è®­ç»ƒ k-NN (k={k})...")
    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')
    knn.fit(train_features, train_labels)
    
    print("é¢„æµ‹...")
    pred_labels = knn.predict(val_features)
    accuracy = accuracy_score(val_labels, pred_labels)
    
    return accuracy


# ============================================================
# 3. Linear Probe è¯„ä¼°
# ============================================================

def linear_probe_eval(
    train_features: np.ndarray,
    train_labels: np.ndarray,
    val_features: np.ndarray,
    val_labels: np.ndarray,
    max_iter: int = 1000,
    C: float = 1.0
) -> float:
    """
    ä½¿ç”¨ Linear Probe è¯„ä¼°
    
    Args:
        train_features: [N_train, feat_dim] è®­ç»ƒé›†ç‰¹å¾
        train_labels: [N_train] è®­ç»ƒé›†æ ‡ç­¾
        val_features: [N_val, feat_dim] éªŒè¯é›†ç‰¹å¾
        val_labels: [N_val] éªŒè¯é›†æ ‡ç­¾
        max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°
        C: æ­£åˆ™åŒ–å¼ºåº¦
    
    Returns:
        accuracy: å‡†ç¡®ç‡
    """
    print(f"è®­ç»ƒ Linear Probe (C={C})...")
    lr = LogisticRegression(
        max_iter=max_iter,
        C=C,
        solver='lbfgs',
        multi_class='multinomial'
    )
    lr.fit(train_features, train_labels)
    
    print("é¢„æµ‹...")
    pred_labels = lr.predict(val_features)
    accuracy = accuracy_score(val_labels, pred_labels)
    
    return accuracy


# ============================================================
# 4. å®Œæ•´è¯„ä¼° Pipeline
# ============================================================

def evaluate_model(
    model: nn.Module,
    train_loader: DataLoader,
    val_loader: DataLoader,
    device: torch.device,
    eval_method: str = "knn",  # "knn" æˆ– "linear_probe"
    use_cls_token: bool = False,
    knn_k: int = 20,
    linear_probe_C: float = 1.0,
    disable_tqdm: bool = False
) -> Dict[str, float]:
    """
    å®Œæ•´çš„è¯„ä¼° pipeline
    
    Args:
        model: ç¼–ç å™¨æ¨¡å‹
        train_loader: è®­ç»ƒé›†æ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºæ„å»º feature bankï¼‰
        val_loader: éªŒè¯é›†æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        eval_method: "knn" æˆ– "linear_probe"
        use_cls_token: æ˜¯å¦ä½¿ç”¨ CLS tokenï¼ˆViTï¼‰
        knn_k: k-NN çš„ k å€¼
        linear_probe_C: Linear Probe çš„æ­£åˆ™åŒ–å¼ºåº¦
        disable_tqdm: æ˜¯å¦ç¦ç”¨ tqdm è¿›åº¦æ¡
    
    Returns:
        results: è¯„ä¼°ç»“æœå­—å…¸
    """
    print("=" * 60)
    print("å¼€å§‹è¯„ä¼°...")
    print("=" * 60)
    
    # æå–ç‰¹å¾
    print("\n1. æå–è®­ç»ƒé›†ç‰¹å¾...")
    train_features, train_labels = extract_features(
        model, train_loader, device, use_cls_token, disable_tqdm
    )
    print(f"   è®­ç»ƒé›†ç‰¹å¾å½¢çŠ¶: {train_features.shape}")
    if train_labels is not None:
        print(f"   è®­ç»ƒé›†æ ‡ç­¾èŒƒå›´: [{train_labels.min()}, {train_labels.max()}], ç±»åˆ«æ•°: {len(np.unique(train_labels))}")
        print(f"   è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(train_labels.astype(int))[:10]}... (å‰10ä¸ªç±»åˆ«)")
    
    print("\n2. æå–éªŒè¯é›†ç‰¹å¾...")
    val_features, val_labels = extract_features(
        model, val_loader, device, use_cls_token, disable_tqdm
    )
    print(f"   éªŒè¯é›†ç‰¹å¾å½¢çŠ¶: {val_features.shape}")
    if val_labels is not None:
        print(f"   éªŒè¯é›†æ ‡ç­¾èŒƒå›´: [{val_labels.min()}, {val_labels.max()}], ç±»åˆ«æ•°: {len(np.unique(val_labels))}")
        print(f"   éªŒè¯é›†æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(val_labels.astype(int))[:10]}... (å‰10ä¸ªç±»åˆ«)")
    
    # è¯„ä¼°
    print(f"\n3. {eval_method} è¯„ä¼°...")
    if eval_method == "knn":
        accuracy = knn_eval(
            train_features, train_labels,
            val_features, val_labels,
            k=knn_k
        )
    elif eval_method == "linear_probe":
        accuracy = linear_probe_eval(
            train_features, train_labels,
            val_features, val_labels,
            C=linear_probe_C
        )
    else:
        raise ValueError(f"Unknown eval_method: {eval_method}")
    
    results = {
        "accuracy": accuracy,
        "eval_method": eval_method
    }
    
    print(f"\nâœ… è¯„ä¼°å®Œæˆ: {eval_method} accuracy = {accuracy:.4f}")
    print("=" * 60)
    
    return results


# ============================================================
# 5. CUB æ•°æ®é›†åŠ è½½ï¼ˆç”¨äºè¯„ä¼°ï¼‰
# ============================================================

class CUBDataset(Dataset):
    """CUB-200-2011 æ•°æ®é›†"""
    
    def __init__(self, image_dir, labels_csv=None, transform=None):
        """
        Args:
            image_dir: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
            labels_csv: æ ‡ç­¾CSVæ–‡ä»¶ï¼ˆtrain/valæœ‰ï¼Œtestæ²¡æœ‰ï¼‰
            transform: å›¾åƒå˜æ¢
        """
        self.image_dir = Path(image_dir)
        self.transform = transform
        
        # åŠ è½½æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ï¼‰
        if labels_csv is not None:
            self.labels_df = pd.read_csv(labels_csv)
            self.has_labels = True
        else:
            # Test set: åªæœ‰å›¾ç‰‡åˆ—è¡¨
            self.labels_df = pd.DataFrame({
                'filename': [f.name for f in self.image_dir.glob('*.jpg')]
            })
            self.has_labels = False
        
        print(f"âœ” Loaded {len(self.labels_df)} images from {image_dir}")
    
    def __len__(self):
        return len(self.labels_df)
    
    def __getitem__(self, idx):
        row = self.labels_df.iloc[idx]
        
        # åŠ è½½å›¾ç‰‡
        img_path = self.image_dir / row['filename']
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        if self.has_labels:
            label = row['class_id']
            return img, label
        else:
            return img


def load_cub_data(data_dir, img_size=96, batch_size=256, num_workers=4):
    """
    åŠ è½½ CUB-200-2011 è¯„ä¼°æ•°æ®
    
    Args:
        data_dir: kaggle_data/ æ–‡ä»¶å¤¹è·¯å¾„
        img_size: å›¾åƒå°ºå¯¸
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        
    Returns:
        train_loader: è®­ç»ƒé›†ï¼ˆç”¨äº k-NN feature bankï¼‰
        val_loader: éªŒè¯é›†ï¼ˆç”¨äºè¯„ä¼°ï¼‰
    """
    data_dir = Path(data_dir)
    
    # å›¾åƒå˜æ¢ï¼ˆä¸åšå¢å¼ºï¼‰
    transform = transforms.Compose([
        transforms.Resize(img_size),
        transforms.CenterCrop(img_size),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = CUBDataset(
        image_dir=data_dir / 'train',
        labels_csv=data_dir / 'train_labels.csv',
        transform=transform
    )
    
    val_dataset = CUBDataset(
        image_dir=data_dir / 'val',
        labels_csv=data_dir / 'val_labels.csv',
        transform=transform
    )
    
    # åˆ›å»º DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    return train_loader, val_loader


# ============================================================
# 6. CUB è¯„ä¼°å‡½æ•°ï¼ˆæ¨¡å—åŒ–ï¼Œå¯åœ¨è®­ç»ƒä¸­ä½¿ç”¨ï¼‰
# ============================================================

def evaluate_on_cub(
    method: nn.Module,
    cub_data_dir: str,
    device: torch.device,
    img_size: int = 96,
    batch_size: int = 256,
    num_workers: int = 4,
    eval_method: str = "knn",
    use_cls_token: bool = False,
    knn_k: int = 20,
    linear_probe_C: float = 1.0,
    verbose: bool = True,
    disable_tqdm: bool = False
) -> Dict[str, float]:
    """
    åœ¨ CUB-200-2011 ä¸Šè¯„ä¼°æ¨¡å‹ï¼ˆæ¨¡å—åŒ–å‡½æ•°ï¼Œå¯åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨ï¼‰
    
    Args:
        method: è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å®ä¾‹ï¼ˆéœ€è¦å®ç° get_encoder() æ–¹æ³•ï¼‰
        cub_data_dir: CUB æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆåŒ…å« train/val/testï¼‰
        device: è®¾å¤‡
        img_size: å›¾åƒå°ºå¯¸
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        eval_method: è¯„ä¼°æ–¹æ³•ï¼Œ"knn" æˆ– "linear_probe"
        use_cls_token: æ˜¯å¦ä½¿ç”¨ CLS tokenï¼ˆä»… ViTï¼‰
        knn_k: k-NN çš„ k å€¼
        linear_probe_C: Linear Probe çš„æ­£åˆ™åŒ–å¼ºåº¦
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        disable_tqdm: æ˜¯å¦ç¦ç”¨ tqdm è¿›åº¦æ¡
    
    Returns:
        results: è¯„ä¼°ç»“æœå­—å…¸ï¼ŒåŒ…å« accuracy å’Œ eval_method
    """
    if verbose:
        print("\n" + "="*60)
        print("ğŸ“Š åœ¨ CUB-200-2011 ä¸Šè¯„ä¼°æ¨¡å‹...")
        print("="*60)
    
    # åŠ è½½ CUB æ•°æ®
    if verbose:
        print("åŠ è½½ CUB-200-2011 æ•°æ®é›†...")
    train_loader, val_loader = load_cub_data(
        cub_data_dir,
        img_size=img_size,
        batch_size=batch_size,
        num_workers=num_workers
    )
    
    # è·å–ç¼–ç å™¨ï¼ˆå†»ç»“ï¼‰
    encoder = method.get_encoder()
    encoder.eval()
    
    # è¯„ä¼°
    results = evaluate_model(
        model=encoder,
        train_loader=train_loader,
        val_loader=val_loader,
        device=device,
        eval_method=eval_method,
        use_cls_token=use_cls_token,
        knn_k=knn_k,
        linear_probe_C=linear_probe_C,
        disable_tqdm=disable_tqdm
    )
    
    if verbose:
        print(f"\nğŸ¯ CUB-200-2011 {eval_method} å‡†ç¡®ç‡: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)")
        print("="*60)
    
    return results

